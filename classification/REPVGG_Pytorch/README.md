# RepVGG: Making VGG-style ConvNets Great Again Pytorch Implementation


```bash
$ python3 main.py 
```

## References

* **Title**:RepVGG: Making VGG-style ConvNets Great Again
* **Authors**: Xiaohan Ding,  Xiangyu Zhang,  Ningning Ma, 
Jungong Han,  Guiguang Ding, Jian Sun 
* **Link**: https://arxiv.org/pdf/2101.03697.pdf
* **Year**: 2021

## Contributed by:
* [Imad Khan](https://github.com/imad08)

# Summary 

REPVGG is a simple but powerful architecture of CNN which has a VGG like inference time .It runs 101% faster then 
![a block in residual network](https://www.google.com/url?sa=i&url=https%3A%2F%2Fwww.arxiv-vanity.com%2Fpapers%2F2101.03697%2F&psig=AOvVaw1iXo5RHJKraeTNj0Hz1b8C&ust=1623949300283000&source=images&cd=vfe&ved=0CAIQjRxqFwoTCKC-udzQnPECFQAAAAAdAAAAABAD)
## Architecture of StackGAN



## model summary 
Reparamateriztion is key in 
### before reparamaterization 

1hr 58min 43sec 80 epoch 
accuracy approx 86%

Total params: 15,681,066

Trainable params: 15,681,066

Non-trainable params: 0

Params size (MB): 59.82

Estimated Total Size (MB): 196.78

### After reparametrization 

1hr 0 min 33 se 

accuracy 84%

Total params: 7,041,194

Trainable params: 7,041,194 

Non Trainable params :0 

Params size (MB): 26.86

Estimated Total Size (MB): 54.82

## Results

### Combined Losses For Generator And Discriminator
